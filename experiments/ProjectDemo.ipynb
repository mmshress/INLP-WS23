{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQsOvaiou5CQ",
        "outputId": "794c36a6-a6aa-42b9-d2d6-319a5c90ee7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGJz_AY81cUZ",
        "outputId": "8df36a8f-6681-489d-8ac3-703d9f234837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (3.17.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLwcogKb1j03"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers einops accelerate langchain bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k07_cg3K1qVM"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Sz1RFO31q1D"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybttaB6h1tvb"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
        "\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
        "from llama_index.llms import HuggingFaceLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnw7oAQq3eq8"
      },
      "outputs": [],
      "source": [
        "\n",
        "from llama_index.prompts.prompts import SimpleInputPrompt\n",
        "\n",
        "\n",
        "system_prompt = \"You are a Q&A assistant. Your goal is to answer questions as accurately as possible based on the instructions and context provided.\"\n",
        "\n",
        "\n",
        "\n",
        "# This will wrap the default prompts that are internal to llama-index\n",
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLxWuFdg1ziK"
      },
      "outputs": [],
      "source": [
        "documents = SimpleDirectoryReader('/content/drive/MyDrive/data').load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMTfEL5p15z4"
      },
      "outputs": [],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN5j7PLN2D5T"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    context_window=4096,\n",
        "    max_new_tokens=256,\n",
        "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
        "    system_prompt=system_prompt,\n",
        "    query_wrapper_prompt=query_wrapper_prompt,\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    device_map=\"auto\",\n",
        "    # uncomment this if using CUDA to reduce memory usage\n",
        "    model_kwargs={\"torch_dtype\": torch.float16 , \"load_in_8bit\":True}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbAEto-82FHI"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "from llama_index import ServiceContext\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(model_name=\"WhereIsAI/UAE-Large-V1\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from llama_index.node_parser import LangchainNodeParser\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1024,\n",
        "    chunk_overlap=40,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "parser = LangchainNodeParser(text_splitter)\n",
        "nodes = parser.get_nodes_from_documents(documents)"
      ],
      "metadata": {
        "id": "xvfritKq5RMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_cb6iNNV9dgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wik5LSG62L1q"
      },
      "outputs": [],
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    chunk_size=1024,\n",
        "    llm=llm,\n",
        "    embed_model=embed_model\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1rRvfe1oGYi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Ie6MKs9U4s"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.retrievers import BM25Retriever\n",
        "\n",
        "vector_retriever = index.as_retriever(similarity_top_k=10)\n",
        "\n",
        "bm25_retriever = BM25Retriever.from_defaults(\n",
        "    docstore=index.docstore, similarity_top_k=10\n",
        ")\n",
        "\n",
        "from llama_index.retrievers import QueryFusionRetriever\n",
        "\n",
        "retriever = QueryFusionRetriever(\n",
        "    [vector_retriever, bm25_retriever],\n",
        "    similarity_top_k=2,\n",
        "    num_queries=1,  # setting this to 1 to disable query generation\n",
        "    mode=\"reciprocal_rerank\",\n",
        "    use_async=True,\n",
        "    verbose=True,\n",
        "\n",
        ")\n",
        "\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "\n",
        "query_engine = RetrieverQueryEngine.from_args(retriever)"
      ],
      "metadata": {
        "id": "h9SjUsCLGc31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnSuhKdG2QKB"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(\" Commission acting in accordance with the procedure laid down in article 251 of The Treaty. State the treaty here.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_Zxatbm2Rr4"
      },
      "outputs": [],
      "source": [
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = query_engine.query(\"State all the treaties mentioned in text\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "bxVc0QhPgzmr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}