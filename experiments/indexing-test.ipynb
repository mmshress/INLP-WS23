{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the pdf into text files to maintiain the line and spacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Difference in pages can be used for splitbypages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = None\n",
    "with open(\"test-data/pdfs/32008R1099.pdf\", \"rb\") as pdf:\n",
    "    reader = PyPDF2.PdfReader(pdf)\n",
    "\n",
    "    for page_number, page in enumerate(reader.pages):\n",
    "        if page_number == 0:\n",
    "            document = page.extract_text()\n",
    "        document += \"\\n====================\\n\" + page.extract_text()\n",
    "        # document += page.extract_text()\n",
    "\n",
    "with open(\"test-data/txts/32008R1099-paged-formated-PyPDF2.txt\", \"w\", encoding=\"utf-8\") as textfile:\n",
    "    textfile.write(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No difference in pages can be used for splitbylines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = None\n",
    "with open(\"test-data/pdfs/32008R1099.pdf\", \"rb\") as pdf:\n",
    "    reader = PyPDF2.PdfReader(pdf)\n",
    "\n",
    "    for page_number, page in enumerate(reader.pages):\n",
    "        if page_number == 0:\n",
    "            document = page.extract_text()\n",
    "        # document += \"\\n====================\\n\" + page.extract_text()\n",
    "        document += page.extract_text()\n",
    "\n",
    "with open(\"test-data/txts/32008R1099-formated-PyPDF2.txt\", \"w\", encoding=\"utf-8\") as textfile:\n",
    "    textfile.write(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the text files and convert them to chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk by pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-data/txts/32008R1099-paged-formated-PyPDF2.txt\", \"rb\") as testfile:\n",
    "    document = testfile.read().decode(\"utf-8\")\n",
    "\n",
    "    for page_number, page in enumerate(document.split(\"\\n====================\\n\")):\n",
    "        with open(f\"test-data/chunks/1p-32008R1099/{page_number}.txt\", \"w\") as chunkfile:\n",
    "            chunkfile.write(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunk by number of lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test-data/txts/32008R1099-formated-PyPDF2.txt\", \"rb\") as testfile:\n",
    "    document = testfile.read().decode(\"utf-8\")\n",
    "\n",
    "    chunk = ''\n",
    "    for line_number, line in enumerate(document.splitlines(keepends=True)):\n",
    "        if line_number == 0:\n",
    "            chunk = line\n",
    "            continue\n",
    "\n",
    "        if line_number % 1 == 0 and not line_number == 0:\n",
    "            with open(f\"test-data/chunks/1l-32008R1099/{line_number}.txt\", \"w\") as chunkfile:\n",
    "                chunkfile.write(chunk)\n",
    "                chunk = ''\n",
    "\n",
    "        chunk += line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spacy_textspiltter\n",
    "- chunk_size and chunk_overlap\n",
    "\n",
    "- create a AST for documents\n",
    "- then embed it? :O\n",
    "- check hyphenations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/.config/python.env/nlptrans.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/.config/python.env/nlptrans.env/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "transformer = SentenceTransformer(\"flax-sentence-embeddings/all_datasets_v4_MiniLM-L6\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "files = os.listdir(\"test-data/chunks/1p-32008R1099/\")\n",
    "\n",
    "embeddings = []\n",
    "for file in files:\n",
    "    if os.path.isfile(f\"test-data/chunks/1p-32008R1099/{file}\"):\n",
    "        with open(f\"test-data/chunks/1p-32008R1099/{file}\", \"r\") as file:\n",
    "            embedding = transformer.encode(file.read())\n",
    "\n",
    "    embeddings.append(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embed user query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a legal agent of EU law of regulations. \n",
    "You will summarize the laws that are provided to you in the query and \n",
    "analyze the question and related answers then formulate a proper response to \n",
    "the query that even a lay person can understand.\"\"\"\n",
    "\n",
    "user_query = \"What is this regulation for?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_query = transformer.encode(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find similar chunks to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = cosine_similarity(np.expand_dims(embedded_query, axis=0), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_similarities = sorted(cosine_similarities[0])\n",
    "\n",
    "top_indices = []\n",
    "for index, sim in enumerate(cosine_similarities[0]):\n",
    "    if sim in sorted_similarities[-5:]:\n",
    "        top_indices.append((index, sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 0.38801306)\n",
      "(26, 0.49764177)\n",
      "(37, 0.30940196)\n",
      "(50, 0.5452769)\n",
      "(54, 0.38801306)\n"
     ]
    }
   ],
   "source": [
    "for i in top_indices:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlptrans.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
