{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: evaluate in ./.venv/lib/python3.11/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./.venv/lib/python3.11/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in ./.venv/lib/python3.11/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.11/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.11/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./.venv/lib/python3.11/site-packages (from evaluate) (0.21.3)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: responses<0.19 in ./.venv/lib/python3.11/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: rouge_score in ./.venv/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in ./.venv/lib/python3.11/site-packages (from rouge_score) (2.1.0)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in ./.venv/lib/python3.11/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk->rouge_score) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.11/site-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from nltk->rouge_score) (4.66.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: bert_score in ./.venv/lib/python3.11/site-packages (0.3.13)\n",
      "Requirement already satisfied: torch>=1.0.0 in ./.venv/lib/python3.11/site-packages (from bert_score) (2.2.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in ./.venv/lib/python3.11/site-packages (from bert_score) (2.2.1)\n",
      "Requirement already satisfied: transformers>=3.0.0 in ./.venv/lib/python3.11/site-packages (from bert_score) (4.38.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from bert_score) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in ./.venv/lib/python3.11/site-packages (from bert_score) (4.66.2)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (from bert_score) (3.8.3)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from bert_score) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=1.0.1->bert_score) (2024.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (4.10.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (3.1.3)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in ./.venv/lib/python3.11/site-packages (from torch>=1.0.0->bert_score) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score) (12.3.101)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.11/site-packages (from transformers>=3.0.0->bert_score) (0.21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from transformers>=3.0.0->bert_score) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers>=3.0.0->bert_score) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.11/site-packages (from transformers>=3.0.0->bert_score) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./.venv/lib/python3.11/site-packages (from transformers>=3.0.0->bert_score) (0.4.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->bert_score) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib->bert_score) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->bert_score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib->bert_score) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib->bert_score) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->bert_score) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->bert_score) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->bert_score) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->bert_score) (2024.2.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.0.0->bert_score) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install evaluate\n",
    "%pip install rouge_score\n",
    "%pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Downloads/responses/responses_Splitter_text_bm25.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data1 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Downloads/responses/responses_Splitter_sentence_bm25.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Downloads/responses/responses_Splitter_Recursive_bm25.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data3 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Downloads/responses/responses_Splitter_semantic_UAE_emb_bm25.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data4 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Downloads/responses/responses_Splitter_semantic_stella_emb_bm25.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data5 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_semantic_UAE_emb_fusion.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data1_fusion = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_text_UAE_emb_fusion.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data2_fusion = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project/responses/responses_Splitter_semantic_stella_emb_fusion.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data3_fusion = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_text_UAE_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data1_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_text_stella_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data2_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_sentence_UAE_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data3_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_sentence_stella_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data4_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_Recursive_UAE_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data5_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_Recursive_stella_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data6_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_semantic_UAE_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data7_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    " \n",
    "# Opening JSON file\n",
    "f = open('/home/siddhant/Documents/INLP_Project//responses/responses_Splitter_semantic_stella_emb_vector.jsonl')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "data8_vector = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  open('/home/siddhant/Downloads/LabelledRAGQAcombined.json')\n",
    " \n",
    "# returns JSON object as \n",
    "# a dictionary\n",
    "reference_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data1, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "### your code ###\n",
    "\n",
    "bertscore = evaluate.load(\"bertscore\")\n",
    "### your code ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8939902079105377, 'recall': 0.9170813596248627, 'f1': 0.9050439453125}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_text_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8943151962757111, 'recall': 0.916894736289978, 'f1': 0.9051207947731018}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data2, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_sentence_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8988364887237549, 'recall': 0.8957296168804169, 'f1': 0.8969345331192017}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data3, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_Recursive_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8918967282772065, 'recall': 0.9163548803329468, 'f1': 0.9035008692741394}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data4, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_semantic_UAE_emb_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8947973608970642, 'recall': 0.9177642798423767, 'f1': 0.9056237137317658}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data5, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_semantic_stella_emb_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8943526029586792, 'recall': 0.9173713493347168, 'f1': 0.905246753692627}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data1_fusion, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_semantic_UAE_emb_fusion.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8952781248092652, 'recall': 0.9153989219665527, 'f1': 0.9048677229881287}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data2_fusion, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_text_UAE_emb_fusion.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8946832287311554, 'recall': 0.9148807775974274, 'f1': 0.9042734026908874}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data3_fusion, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"generated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_semantic_stella_emb_fusion.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8934041047096253, 'recall': 0.9115172910690308, 'f1': 0.901931985616684}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data1_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_text_UAE_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8891841578483581, 'recall': 0.9076213407516479, 'f1': 0.8978427994251251}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data2_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_text_stella_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8934041047096253, 'recall': 0.9115172910690308, 'f1': 0.901931985616684}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data3_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_sentence_UAE_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8894051718711853, 'recall': 0.9077438426017761, 'f1': 0.8980195951461792}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data4_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_sentence_stella_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.9013001465797424, 'recall': 0.9012961995601654, 'f1': 0.9009653556346894}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data5_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_Recursive_UAE_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.9056412971019745, 'recall': 0.9058537876605988, 'f1': 0.9054380095005036}\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data6_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_Recursive_stella_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8753716635704041, 'recall': 0.8970409047603607, 'f1': 0.8854834866523743}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data7_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"geneated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_semantic_UAE_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8783851718902588, 'recall': 0.8980078542232514, 'f1': 0.8877831947803497}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Empty candidate sentence detected; setting raw BERTscores to 0.\n"
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "reference = []\n",
    "for index, (data, refs) in enumerate(zip(data8_vector, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    answer.append(data[\"generated_response\"])\n",
    "    reference.append(refs[\"answer\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=answer, references=reference, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_responses_Splitter_semantic_stella_emb_vector.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.7902095425128937, 'recall': 0.8959955668449402, 'f1': 0.8391547310352325}\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "reference_context = []\n",
    "for index, (data, refs) in enumerate(zip(data1, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    context.append(data[\"retrieved_context\"])\n",
    "    reference_context.append(refs[\"context\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=context, references=reference_context, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_context_responses_Splitter_text_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.7902095425128937, 'recall': 0.8959955668449402, 'f1': 0.8391547310352325}\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "reference_context = []\n",
    "for index, (data, refs) in enumerate(zip(data2, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    context.append(data[\"retrieved_context\"])\n",
    "    reference_context.append(refs[\"context\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=context, references=reference_context, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_context_responses_Splitter_sentence_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.8575796341896057, 'recall': 0.8928592538833618, 'f1': 0.8741227900981903}\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "reference_context = []\n",
    "for index, (data, refs) in enumerate(zip(data3, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    context.append(data[\"retrieved_context\"])\n",
    "    reference_context.append(refs[\"context\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=context, references=reference_context, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_context_responses_Splitter_Recursive_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.7771985828876495, 'recall': 0.8698320817947388, 'f1': 0.8204517722129822}\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "reference_context = []\n",
    "for index, (data, refs) in enumerate(zip(data4, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    context.append(data[\"retrieved_context\"])\n",
    "    reference_context.append(refs[\"context\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=context, references=reference_context, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_context_responses_Splitter_semantic_UAE_emb_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple system:\n",
      "{'precision': 0.779626430273056, 'recall': 0.8723033392429351, 'f1': 0.8228457260131836}\n"
     ]
    }
   ],
   "source": [
    "context = []\n",
    "reference_context = []\n",
    "for index, (data, refs) in enumerate(zip(data5, reference_data)):\n",
    "    if index >= 50:\n",
    "        break\n",
    "    context.append(data[\"retrieved_context\"])\n",
    "    reference_context.append(refs[\"context\"])\n",
    "\n",
    "import numpy as np\n",
    "### your code ###\n",
    "bertscore_simple = bertscore.compute(predictions=context, references=reference_context, lang=\"en\")\n",
    "bertscore_simple_averaged={}\n",
    "for key in bertscore_simple.keys():\n",
    "  if key!='hashcode':\n",
    "    bertscore_simple_averaged[key]=np.mean(bertscore_simple[key])\n",
    "\n",
    "### your code ###\n",
    "print(\"Simple system:\")\n",
    "print(bertscore_simple_averaged)\n",
    "\n",
    "with open(f\"/home/siddhant/Documents/INLP_Project/bert_context_responses_Splitter_semantic_stella_emb_bm25.jsonl\", \"w\") as file:\n",
    "    json.dump(bertscore_simple, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
